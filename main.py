import json, os, redis
from datetime import datetime, timedelta
from typing import Optional, List

from fastapi import FastAPI, Depends, HTTPException, Header, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, ConfigDict
from sqlalchemy import String, ForeignKey, DateTime, Boolean, create_engine
from sqlalchemy.orm import Mapped, mapped_column, relationship, Session
from sqlalchemy.dialects.postgresql import JSON

from database import Base, engine, get_db
from tasks.reporting import generate_report

import logging
import json
import uuid
import time
from starlette.middleware.base import BaseHTTPMiddleware
from fastapi.responses import JSONResponse
import traceback
from prometheus_fastapi_instrumentator import Instrumentator



# JSON logger configuration
logger = logging.getLogger("psychologist health")
logger.propagate = False
logger.setLevel(logging.INFO)

handler = logging.StreamHandler()
handler.setLevel(logging.INFO)

class JsonRequestFormatter(logging.Formatter):
    def format(self, record: logging.LogRecord) -> str:
        # Start from message or dict payload
        if isinstance(record.msg, dict):
            log_record = dict(record.msg)  # shallow copy to avoid mutating original
        else:
            log_record = {"message": record.getMessage()}

        log_record.setdefault("level", record.levelname)
        log_record.setdefault("logger", record.name)

        # Keys from LogRecord we do NOT want to copy (internal fields)
        reserved_keys = {
            "message",
            "msg",
            "args",
            "name",
            "levelname",
            "levelno",
        }

        # Merge extra fields into log_record
        for key, value in record.__dict__.items():
            if key in reserved_keys:
                continue
            log_record[key] = value

        return json.dumps(log_record, ensure_ascii=False)


handler.setFormatter(JsonRequestFormatter())
logger.handlers.clear()
logger.addHandler(handler)


# Initialize FastAPI app
app = FastAPI()

# This automatically adds /metrics
Instrumentator().instrument(app).expose(app)

# Explicit list of allowed frontend origins
origins = [
    "http://localhost:3000",          # Local React dev server
    "https://phs-70gu.onrender.com",  # Deployed frontend on Render
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class RequestLoggingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        request_id = str(uuid.uuid4())
        # store on request.state so handlers can use it later if needed
        request.state.request_id = request_id
        start_time = time.perf_counter()
        response = await call_next(request)
        # compute latency in ms
        latency_ms = (time.perf_counter() - start_time) * 1000
        # response.headers["Access-Control-Allow-Origin"]  = "https://phs-70gu.onrender.com"
        # response.headers["Access-Control-Allow-Headers"] = "*"
        # response.headers["Access-Control-Allow-Methods"] = "*"
        response.headers["X-Request-ID"] = request_id
        user_agent = request.headers.get("User-Agent", "unknown")
        route_name = request.scope.get("route").name if request.scope.get("route") else "unknown"

        log_data = {
            "request_id": request_id,
            "method": request.method,
            "path": request.url.path,
            "status": response.status_code,
            "client": request.client.host if request.client else None,
            "latency_ms": round(latency_ms, 2),  # round to 2 decimals
            "user_agent": user_agent,
            "route": route_name
        }
        logger.info("http_request", extra=log_data)
        
        return response

app.add_middleware(RequestLoggingMiddleware)


@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """
    Catch-all exception handler for unexpected server-side errors.
    This will capture any exception that is NOT an HTTPException.

    Responsibilities:
    - Ensure every error response includes a request_id for traceability.
    - Log the stack trace and key context for debugging (structured logs).
    - Prevent leaking internal error details to the client.
    """

    # Retrieve request_id generated by RequestLoggingMiddleware
    request_id = getattr(request.state, "request_id", None)

    # Fallback: generate a new one if middleware didn't run or failed early
    if request_id is None:
        request_id = str(uuid.uuid4())

    # structured logging for debugging & observability
    logger.error(
        "Unhandled server-side exception",
        extra={
            "request_id": request_id,
            "path": request.url.path,
            "method": request.method,
            "error_type": exc.__class__.__name__,
            "error_message": str(exc),
            "stack_trace": traceback.format_exc(),
        },
    )

    # return safe JSON response to the client
    return JSONResponse(
        status_code=500,
        content={
            "detail": "Internal server error",
            "request_id": request_id,
        },
    )

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    request_id = getattr(request.state, "request_id", None)

    if request_id is None:
        # Very defensive fallback, should rarely happen for HTTPException
        request_id = str(uuid.uuid4())

    logger.warning(
        "HTTPException encountered",
        extra={
            "request_id": request_id,
            "path": request.url.path,
            "method": request.method,
            "status_code": exc.status_code,
            "detail": exc.detail,
        },
    )

    return JSONResponse(
        status_code=exc.status_code,
        content={
            "detail": exc.detail,
            "request_id": request_id,
        },
    )


# Redis client
r = redis.from_url(os.getenv("REDIS_URL", "redis://redis:6379/0"))

# SQLAlchemy Models
class Psychologist(Base):
    __tablename__ = "psychologist"
    id: Mapped[int] = mapped_column(primary_key=True)
    name: Mapped[str] = mapped_column(String(30))
    bookings: Mapped[list["Booking"]] = relationship("Booking", back_populates="psychologist")

class Client(Base):
    __tablename__ = "client"
    id: Mapped[int] = mapped_column(primary_key=True)
    name: Mapped[str] = mapped_column(String(30))
    booking: Mapped["Booking"] = relationship("Booking", back_populates="client")

class Booking(Base):
    __tablename__ = "booking"
    id: Mapped[int] = mapped_column(primary_key=True)
    date_time: Mapped[datetime] = mapped_column(DateTime, nullable=False)
    is_recurring: Mapped[bool] = mapped_column(Boolean, default=False)
    exceptions: Mapped[Optional[list]] = mapped_column(JSON, nullable=True)
    status: Mapped[str] = mapped_column(String(20), default='Pending')
    client_id: Mapped[int] = mapped_column(ForeignKey("client.id"), unique=True)
    client: Mapped["Client"] = relationship("Client", back_populates="booking")
    psychologist_id: Mapped[int] = mapped_column(ForeignKey("psychologist.id"))
    psychologist: Mapped["Psychologist"] = relationship("Psychologist", back_populates="bookings")

# Pydantic Schemas for data validation and serialization
class BookingBase(BaseModel):
    date_time: datetime
    is_recurring: bool = False

class BookingCreate(BaseModel):
    client_name: str
    psychologist_id: int
    date_time: str # Assuming ISO format string from frontend
    timezoneOffset: int
    is_recurring: bool = False

class BookingUpdate(BaseModel):
    newDateTime: str
    timezoneOffset: int

class ExceptionCreate(BaseModel):
    exception_date: str
    timezoneOffset: int

class BookingSchema(BookingBase):
    model_config = ConfigDict(from_attributes=True)
    id: int
    status: str
    client_id: int
    psychologist_id: int
    exceptions: Optional[list] = None

@app.get("/test-http-exception")
async def test_http_exception():
    """
    Test endpoint that always raises HTTPException.
    Should be handled by http_exception_handler.
    """
    raise HTTPException(status_code=403, detail="Test HTTPException - forbidden")


@app.get("/test-global-exception")
async def test_global_exception():
    """
    Test endpoint that always raises a generic exception.
    Should be handled by global_exception_handler.
    """
    raise RuntimeError("Test runtime error for global handler")

@app.get("/debug-file-check")
def debug_file_check():
    return {
        "file_loaded_by_render": "main.py",
        "has_request_id_code": hasattr(RequestLoggingMiddleware, "dispatch"),
        "signature": "v3-hello-test"
    }


@app.post("/reports", status_code=202)
async def create_report(request: Request, idempotency_key: Optional[str] = Header(None)):
    """
    Enqueue a report generation job.

    We use:
    - Idempotency-Key: to deduplicate client requests
    - request_id: to correlate HTTP logs with Celery task logs
    """
    if not idempotency_key:
        raise HTTPException(status_code=400, detail="Missing Idempotency-Key")

    # Fetch any existing completed result based on idempotency key.
    done = r.get(f"done:{idempotency_key}")
    if done:
        return json.loads(done)

    # Try to mark this job as inflight (NX prevents duplicates).
    ok = r.set(f"inflight:{idempotency_key}", "1", nx=True, ex=3600)
    if not ok:
        return {"status": "inflight", "poll": f"/jobs/{idempotency_key}"}

    # Get request body (may be empty).
    payload = await request.json()

    # Grab request_id generated by RequestLoggingMiddleware.
    # Fallback to a new UUID if, for some reason, it is missing.
    request_id = getattr(request.state, "request_id", str(uuid.uuid4()))

    # Enqueue Celery task with both request_id and idempotency key.
    async_res = generate_report.delay(request_id, idempotency_key, payload or {})

    # Store Celery task_id for later polling.
    r.setex(f"task:{idempotency_key}", 3600, async_res.id)

    return {"status": "accepted", "poll": f"/jobs/{idempotency_key}"}


@app.get("/healthz")
def healthz():
    return {"status": "ok"}

@app.get("/jobs/{key}")
def poll_job(key: str):
    done = r.get(f"done:{key}")
    if done:
        return json.loads(done)
    task_id = r.get(f"task:{key}")
    if not task_id:
        raise HTTPException(status_code=404, detail={"status": "unknown"})
    return {"status": "inflight"}

@app.put('/add_exception/{booking_id}/', response_model=BookingSchema)
def add_exception(booking_id: int, data: ExceptionCreate, db: Session = Depends(get_db)):
    booking = db.get(Booking, booking_id)
    if not booking:
        raise HTTPException(status_code=404, detail="Booking not found")

    local_dt = datetime.strptime(data.exception_date, '%Y-%m-%dT%H:%M:%S.%fZ')
    offset = timedelta(minutes=data.timezoneOffset)
    local_time = local_dt - offset

    if booking.exceptions is None:
        booking.exceptions = []
    booking.exceptions.append(local_time.isoformat())
    db.commit()
    db.refresh(booking)
    return booking

@app.post('/book', status_code=201, response_model=BookingSchema)
def book_time(data: BookingCreate, db: Session = Depends(get_db)):
    client = Client(name=data.client_name)
    db.add(client)
    db.commit()
    db.refresh(client)

    local_dt = datetime.strptime(data.date_time, '%Y-%m-%dT%H:%M:%S.%fZ')
    offset = timedelta(minutes=data.timezoneOffset)
    date_time = local_dt - offset

    new_booking = Booking(
        client_id=client.id,
        psychologist_id=data.psychologist_id,
        date_time=date_time,
        is_recurring=data.is_recurring
    )
    db.add(new_booking)
    db.commit()
    db.refresh(new_booking)
    return new_booking

@app.put('/approve/{booking_id}', response_model=BookingSchema)
def approve_booking(booking_id: int, db: Session = Depends(get_db)):
    booking = db.get(Booking, booking_id)
    if not booking:
        raise HTTPException(status_code=404, detail="Booking not found")
    booking.status = 'Approved'
    db.commit()
    db.refresh(booking)
    return booking

@app.put('/modify/{booking_id}', response_model=BookingSchema)
def modify_booking(booking_id: int, data: BookingUpdate, db: Session = Depends(get_db)):
    booking = db.get(Booking, booking_id)
    if not booking:
        raise HTTPException(status_code=404, detail="Booking not found")

    local_dt = datetime.strptime(data.newDateTime, '%Y-%m-%dT%H:%M:%S.%fZ')
    offset = timedelta(minutes=data.timezoneOffset)
    booking.date_time = local_dt - offset
    booking.status = 'Pending'
    db.commit()
    db.refresh(booking)
    return booking

@app.delete('/cancel/{booking_id}')
def cancel_booking(booking_id: int, db: Session = Depends(get_db)):
    booking = db.get(Booking, booking_id)
    if not booking:
        raise HTTPException(status_code=404, detail="Booking not found")

    db.delete(booking)
    db.commit()
    return {"message": "Booking canceled"}

@app.get('/schedule/{psychologist_id}', response_model=List[BookingSchema])
def get_schedule(psychologist_id: int, db: Session = Depends(get_db)):
    bookings = db.query(Booking).filter(Booking.psychologist_id == psychologist_id).all()
    return bookings

@app.on_event("startup")
def startup_event():
    # Create all tables
    Base.metadata.create_all(bind=engine)

    with Session(engine) as session:
        # Check if a Psychologist already exists
        first_psychologist = session.query(Psychologist).first()
        if not first_psychologist:
            # If no psychologist exists, create one
            new_psychologist = Psychologist(name="Dr. Alex")
            session.add(new_psychologist)
            session.commit()
